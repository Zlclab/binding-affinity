{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96ac9b9-cb4f-4735-83a3-94779d223e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Binding_affinity  Ics_charg-charg     NIBa     NIBp  Ics_polar-apolar  \\\n",
      "0                9.3                5   2330.0  20402.0                11   \n",
      "1               13.1                3    919.6  20601.7                19   \n",
      "2                6.4                0   1240.4  10575.6                10   \n",
      "3                5.3                8  23504.0   5740.0                18   \n",
      "4               12.1                9   4672.8  23802.0                15   \n",
      "..               ...              ...      ...      ...               ...   \n",
      "76              10.7                8   9931.6  10468.8                28   \n",
      "77               9.6                4   3800.3   4616.4                15   \n",
      "78               8.8                6   4925.9  13743.8                15   \n",
      "79              14.5                3   2107.5  11862.2                20   \n",
      "80              11.3                0   1283.7  12001.6                10   \n",
      "\n",
      "    Ics_apolar-apolar  %NISapol  %NISpol  \n",
      "0                  25     40.77    31.64  \n",
      "1                  25     38.50    42.52  \n",
      "2                  20     45.03    28.13  \n",
      "3                   2     35.84    35.31  \n",
      "4                  28     34.94    36.46  \n",
      "..                ...       ...      ...  \n",
      "76                 10     27.21    23.12  \n",
      "77                 12     29.48    41.03  \n",
      "78                 19     35.07    28.77  \n",
      "79                 20     35.71    49.41  \n",
      "80                 19     31.83    47.98  \n",
      "\n",
      "[81 rows x 8 columns]\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x297f59940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x2998ffba0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "DNN-based mixed model equation: ΔG = -2.15380 * DNNs_1 + 2.16371 * DNNs_2 + 1.01429 * DNNs_3 + 0.00228\n",
      "DNN-based mixed model相关系数 (R): 0.99\n",
      "DNN-based mixed model均方根误差(RMSE): 0.46\n"
     ]
    }
   ],
   "source": [
    "#our DNN-based mixed model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,PReLU,Input\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random as python_random\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from tensorflow.keras.layers import Layer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "# 读取数据集\n",
    "df=pd.read_csv('UPR dataset.csv')\n",
    "#定义新界面特征\n",
    "df['NIBa'] = df['Ics_charg-polar'] * df['BSApolar']\n",
    "df['NIBp'] = df['Ics_charg-apolar'] * df['BSAapolar']\n",
    "#输入我们的特征集合F\n",
    "feature_set_F = ['NIBa','NIBp','Ics_polar-apolar','Ics_charg-charg','Ics_apolar-apolar','%NISpol','%NISapol']\n",
    "feature_set_F_y=['Binding_affinity','Ics_charg-charg','NIBa','NIBp', 'Ics_polar-apolar','Ics_apolar-apolar','%NISapol','%NISpol']\n",
    "data=df[feature_set_F_y]\n",
    "print(data)\n",
    "\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "cycle_times=3 \n",
    "columnnames=['PReLU1','PReLU2','PReLU3']\n",
    "n_repeats = 10\n",
    "\n",
    "DNNs_average_pred=pd.DataFrame({\"y\":y})\n",
    "activation_pred_data=[]\n",
    "u=0\n",
    "for j in range(cycle_times):\n",
    "    activation_pred_data=[]\n",
    "    random_state_number=[a for a in range(j*10+1,j*10+11)]\n",
    "    for i in range(n_repeats):    \n",
    "        python_random.seed(random_state_number[i])\n",
    "        tf.random.set_seed(random_state_number[i])\n",
    "        # 自定义一输出层加权激活函数\n",
    "        class WeightedSumActivation(Layer):\n",
    "            def __init__(self, alpha=0.49, **kwargs):\n",
    "                super(WeightedSumActivation, self).__init__(**kwargs)\n",
    "                self.alpha = tf.Variable(initial_value=alpha, trainable=True, constraint=lambda x: tf.clip_by_value(x, 0, 1))\n",
    "            def call(self, inputs):\n",
    "                linear = tf.keras.activations.linear(inputs)\n",
    "                relu = tf.keras.activations.relu(inputs)\n",
    "                return self.alpha * linear + (1 - self.alpha) * relu\n",
    "        def create_model(units=64):\n",
    "            model = Sequential([\n",
    "                Input(shape=(X.shape[1],)), \n",
    "                Dense(units),\n",
    "                PReLU(),\n",
    "                Dense(units),\n",
    "                PReLU(),\n",
    "                Dense(units),\n",
    "                PReLU(),\n",
    "                Dense(1), \n",
    "                WeightedSumActivation(alpha=0.49)  # 使用自定义激活函数\n",
    "            ])\n",
    "            model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "            return model\n",
    "        model=KerasRegressor(model=create_model,model__units=64,epochs=100,batch_size=10,verbose=0)\n",
    "        param_grid = {\n",
    "            'epochs': [50, 100],   \n",
    "            'batch_size': [3, 9],\n",
    "            'model__units': [64,128]  \n",
    "        }\n",
    "        grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=4, scoring='neg_mean_absolute_error',verbose=0)\n",
    "        grid_result = grid.fit(X, y)\n",
    "        best_model = create_model(units=grid_result.best_params_['model__units'])\n",
    "        best_model.fit(X, y, epochs=grid_result.best_params_['epochs'], batch_size=grid_result.best_params_['batch_size'], verbose=0)\n",
    "        predictions = best_model.predict(X, verbose=0).flatten() \n",
    "        activation_pred_data.append(predictions)\n",
    "        mae = mean_absolute_error(y, predictions) \n",
    "        r, _ = pearsonr(y, predictions)\n",
    "    DNNs_average_pred[columnnames[u]]=np.mean(activation_pred_data, axis=0)\n",
    "    u=u+1\n",
    "\n",
    "# 建立混合模型\n",
    "x = DNNs_average_pred.iloc[:, 1:].values \n",
    "y = DNNs_average_pred.iloc[:, 0].values  \n",
    "n_splits = 4\n",
    "n_repeats = 10\n",
    "coefficients = []\n",
    "random_state_number=[1,2,3,4,5,6,7,8,9,10]\n",
    "for _ in range(n_repeats): \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state_number[_])\n",
    "    for train_index, test_index in kf.split(x): \n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = sm.OLS(y_train, sm.add_constant(x_train)).fit()\n",
    "        coefficients.append(model.params)\n",
    "\n",
    "# 计算所有回归系数的平均值\n",
    "average_coefficients = np.mean(coefficients, axis=0)\n",
    "variable_names=['DNNs_1','DNNs_2','DNNs_3']\n",
    "intercept = round(average_coefficients[0],5)\n",
    "coef_str = ' + '.join([f'{coef:.5f} * {variable_names[i]}' for i, coef in enumerate(average_coefficients[1:])])\n",
    "regression_equation = f'ΔG = {coef_str} + {intercept}'\n",
    "print('DNN-based mixed model equation:', regression_equation)\n",
    "\n",
    "# 计算DNN-based mixed model的R和RMSE\n",
    "average_coefficients1 = np.mean(coefficients, axis=0)[1:]\n",
    "intercept = average_coefficients[0]\n",
    "y_pred = np.dot(x, average_coefficients1) + intercept\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "R,a= pearsonr(y, y_pred)\n",
    "print(f'DNN-based mixed model相关系数 (R): {R:.2f}')\n",
    "print(f'DNN-based mixed model均方根误差(RMSE): {rmse:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
